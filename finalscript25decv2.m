%% Import data from text file.
% Script for importing data from the following text file:
%
%    /Users/dhruv/Dropbox/uclcs/gc027_programming_business_analytics/coursework/nextbigsounddata/finalnbs.csv
%
% To extend the code to different selected data or a different text file,
% generate a function instead of a script.

% Auto-generated by MATLAB on 2015/12/16 16:35:46

%% Initialize variables.
filename = '/Users/dhruv/Dropbox/uclcs/gc027_programming_business_analytics/coursework/finalsubmission/finalnbs.csv';
delimiter = ',';
startRow = 2;

%% Read columns of data as strings:
% For more information, see the TEXTSCAN documentation.
formatSpec = '%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%q%[^\n\r]';

%% Open the text file.
fileID = fopen(filename,'r');

%% Read columns of data according to format string.
% This call is based on the structure of the file used to generate this
% code. If an error occurs for a different file, try regenerating the code
% from the Import Tool.
dataArray = textscan(fileID, formatSpec, 'Delimiter', delimiter, 'HeaderLines' ,startRow-1, 'ReturnOnError', false);

%% Close the text file.
fclose(fileID);

%% Convert the contents of columns containing numeric strings to numbers.
% Replace non-numeric strings with NaN.
raw = repmat({''},length(dataArray{1}),length(dataArray)-1);
for col=1:length(dataArray)-1
    raw(1:length(dataArray{col}),col) = dataArray{col};
end
numericData = NaN(size(dataArray{1},1),size(dataArray,2));

for col=[5,11]
    % Converts strings in the input cell array to numbers. Replaced non-numeric
    % strings with NaN.
    rawData = dataArray{col};
    for row=1:size(rawData, 1);
        % Create a regular expression to detect and remove non-numeric prefixes and
        % suffixes.
        regexstr = '(?<prefix>.*?)(?<numbers>([-]*(\d+[\,]*)+[\.]{0,1}\d*[eEdD]{0,1}[-+]*\d*[i]{0,1})|([-]*(\d+[\,]*)*[\.]{1,1}\d+[eEdD]{0,1}[-+]*\d*[i]{0,1}))(?<suffix>.*)';
        try
            result = regexp(rawData{row}, regexstr, 'names');
            numbers = result.numbers;
            
            % Detected commas in non-thousand locations.
            invalidThousandsSeparator = false;
            if any(numbers==',');
                thousandsRegExp = '^\d+?(\,\d{3})*\.{0,1}\d*$';
                if isempty(regexp(thousandsRegExp, ',', 'once'));
                    numbers = NaN;
                    invalidThousandsSeparator = true;
                end
            end
            % Convert numeric strings to numbers.
            if ~invalidThousandsSeparator;
                numbers = textscan(strrep(numbers, ',', ''), '%f');
                numericData(row, col) = numbers{1};
                raw{row, col} = numbers{1};
            end
        catch me
        end
    end
end

% Convert the contents of columns with dates to MATLAB datetimes using date
% format string.
try
    dates{9} = datetime(dataArray{9}, 'Format', 'MM/dd/yyyy HH:mm', 'InputFormat', 'MM/dd/yyyy HH:mm');
catch
    try
        % Handle dates surrounded by quotes
        dataArray{9} = cellfun(@(x) x(2:end-1), dataArray{9}, 'UniformOutput', false);
        dates{9} = datetime(dataArray{9}, 'Format', 'MM/dd/yyyy HH:mm', 'InputFormat', 'MM/dd/yyyy HH:mm');
    catch
        dates{9} = repmat(datetime([NaN NaN NaN]), size(dataArray{9}));
    end
end

anyBlankDates = cellfun(@isempty, dataArray{9});
anyInvalidDates = isnan(dates{9}.Hour) - anyBlankDates;
dates = dates(:,9);

%% Split data into numeric and cell columns.
rawNumericColumns = raw(:, [5,11]);
rawCellColumns = raw(:, [1,2,3,4,6,7,8,10,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415]);


%% Replace non-numeric cells with NaN
R = cellfun(@(x) ~isnumeric(x) && ~islogical(x),rawNumericColumns); % Find non-numeric cells
rawNumericColumns(R) = {NaN}; % Replace non-numeric cells

%% Create output variable
finalnbs = table;
finalnbs.Firstname = rawCellColumns(:, 1);
finalnbs.Lastname = rawCellColumns(:, 2);
finalnbs.Name = rawCellColumns(:, 3);
finalnbs.Email = rawCellColumns(:, 4);
finalnbs.UserID = cell2mat(rawNumericColumns(:, 1));
finalnbs.FirstSeenEST = rawCellColumns(:, 5);
finalnbs.SignedupEST = rawCellColumns(:, 6);
finalnbs.LastseenEST = rawCellColumns(:, 7);
finalnbs.LastcontactedEST = dates{:, 1};
finalnbs.LastheardfromEST = rawCellColumns(:, 8);
finalnbs.Websessions = cell2mat(rawNumericColumns(:, 2));
finalnbs.Country = rawCellColumns(:, 9);
finalnbs.Region = rawCellColumns(:, 10);
finalnbs.City = rawCellColumns(:, 11);
finalnbs.Timezone = rawCellColumns(:, 12);
finalnbs.BrowserLanguage = rawCellColumns(:, 13);
finalnbs.LanguageOverride = rawCellColumns(:, 14);
finalnbs.Browser = rawCellColumns(:, 15);
finalnbs.BrowserVersion = rawCellColumns(:, 16);
finalnbs.OS = rawCellColumns(:, 17);
finalnbs.KloutScore = rawCellColumns(:, 18);
finalnbs.JobTitle = rawCellColumns(:, 19);
finalnbs.Segment = rawCellColumns(:, 20);
finalnbs.Tag = rawCellColumns(:, 21);
finalnbs.UnsubscribedfromEmails = rawCellColumns(:, 22);
finalnbs.AccountBilling_type = rawCellColumns(:, 23);
finalnbs.AccountBraintree_active = rawCellColumns(:, 24);
finalnbs.AccountBraintree_token = rawCellColumns(:, 25);
finalnbs.AccountCreated_at = rawCellColumns(:, 26);
finalnbs.AccountCreated_by = rawCellColumns(:, 27);
finalnbs.AccountDiscount_rate = rawCellColumns(:, 28);
finalnbs.AccountId = rawCellColumns(:, 29);
finalnbs.AccountIs_enterprise = rawCellColumns(:, 30);
finalnbs.AccountName = rawCellColumns(:, 31);
finalnbs.AccountPrompt_cc = rawCellColumns(:, 32);
finalnbs.AccountPrompt_cc_atEST = rawCellColumns(:, 33);
finalnbs.AccountUser_logins = rawCellColumns(:, 34);
finalnbs.Account_id = rawCellColumns(:, 35);
finalnbs.Account_name = rawCellColumns(:, 36);
finalnbs.Created = rawCellColumns(:, 37);
finalnbs.Email1 = rawCellColumns(:, 38);
finalnbs.Name1 = rawCellColumns(:, 39);
finalnbs.Occupation = rawCellColumns(:, 40);
finalnbs.Organization = rawCellColumns(:, 41);
finalnbs.PackageBilling_cycle = rawCellColumns(:, 42);
finalnbs.PackageBraintree_id = rawCellColumns(:, 43);
finalnbs.PackageDescription = rawCellColumns(:, 44);
finalnbs.PackageName = rawCellColumns(:, 45);
finalnbs.PackagePrice = rawCellColumns(:, 46);
finalnbs.PackageUser_logins = rawCellColumns(:, 47);
finalnbs.access_ADVANCED_EXPORTS = rawCellColumns(:, 48);
finalnbs.access_ALERT_EMAILS = rawCellColumns(:, 49);
finalnbs.access_ANGULAR_SECONDARY_PAGES = rawCellColumns(:, 50);
finalnbs.access_BACK_TO_PREMIER = rawCellColumns(:, 51);
finalnbs.access_CONTENT_IN_GEO_REPORTS = rawCellColumns(:, 52);
finalnbs.access_CONTENT_REPORTS = rawCellColumns(:, 53);
finalnbs.access_CUPID_FILTERS = rawCellColumns(:, 54);
finalnbs.access_DEMOGRAPHICS_REPORT = rawCellColumns(:, 55);
finalnbs.access_ENTERPRISE_ADV_EXPORTS = rawCellColumns(:, 56);
finalnbs.access_ENTERPRISE_PROFILE = rawCellColumns(:, 57);
finalnbs.access_ENTERPRISE_PROFILE_DEV = rawCellColumns(:, 58);
finalnbs.access_FIND = rawCellColumns(:, 59);
finalnbs.access_FIND_ADMIN = rawCellColumns(:, 60);
finalnbs.access_FIND_DB_SELECT = rawCellColumns(:, 61);
finalnbs.access_FIND_ENTITIES_INPUTS = rawCellColumns(:, 62);
finalnbs.access_FIND_FANAXCESS = rawCellColumns(:, 63);
finalnbs.access_FIND_MEDIABASE_FEED = rawCellColumns(:, 64);
finalnbs.access_FIND_PANDORA = rawCellColumns(:, 65);
finalnbs.access_FIND_PREDICTIVE = rawCellColumns(:, 66);
finalnbs.access_FIND_SHAZAM_FEED = rawCellColumns(:, 67);
finalnbs.access_FIND_SPOTIFY_FEED = rawCellColumns(:, 68);
finalnbs.access_FIND_V2 = rawCellColumns(:, 69);
finalnbs.access_FULL_SPOTIFY_FEED_ACCESS = rawCellColumns(:, 70);
finalnbs.access_GA_MACMILLAN_METRICS = rawCellColumns(:, 71);
finalnbs.access_GBP_CONTENT_REPORT = rawCellColumns(:, 72);
finalnbs.access_GBP_GEO_REPORT = rawCellColumns(:, 73);
finalnbs.access_GBP_GRAPHS = rawCellColumns(:, 74);
finalnbs.access_GBP_RANKING_REPORT = rawCellColumns(:, 75);
finalnbs.access_GEOGRAPHIC_REPORTS = rawCellColumns(:, 76);
finalnbs.access_GEO_ZIP3 = rawCellColumns(:, 77);
finalnbs.access_GOODBYE_PREMIER = rawCellColumns(:, 78);
finalnbs.access_GRAPHS3 = rawCellColumns(:, 79);
finalnbs.access_GRAPHS_ANNOTATIONS = rawCellColumns(:, 80);
finalnbs.access_INDUSTRY_REPORT_2012 = rawCellColumns(:, 81);
finalnbs.access_INSIGHTS_BLOGS = rawCellColumns(:, 82);
finalnbs.access_INSIGHTS_TRACK_RELEASES = rawCellColumns(:, 83);
finalnbs.access_IP_TRACKING = rawCellColumns(:, 84);
finalnbs.access_KITCHEN_SINK = rawCellColumns(:, 85);
finalnbs.access_LABS_FORECAST = rawCellColumns(:, 86);
finalnbs.access_LEGACY_FIND = rawCellColumns(:, 87);
finalnbs.access_MACMILLAN_AUTHOR_PROFILE = rawCellColumns(:, 88);
finalnbs.access_METRICS_TEST_SETTING = rawCellColumns(:, 89);
finalnbs.access_MONGO_DOWN = rawCellColumns(:, 90);
finalnbs.access_NBB_ADVANCED_EXPORTS = rawCellColumns(:, 91);
finalnbs.access_NBS_API_REPORT_GENERATOR = rawCellColumns(:, 92);
finalnbs.access_NETWORK_PAGES = rawCellColumns(:, 93);
finalnbs.access_NEW_STORAGE = rawCellColumns(:, 94);
finalnbs.access_NEXT_BIG_BOOK = rawCellColumns(:, 95);
finalnbs.access_POSTAL_SERVICE = rawCellColumns(:, 96);
finalnbs.access_PROFILE_TOP_ASSETS = rawCellColumns(:, 97);
finalnbs.access_RANKING_REPORT = rawCellColumns(:, 98);
finalnbs.access_RANKING_REPORTS = rawCellColumns(:, 99);
finalnbs.access_SMART_EMAILS = rawCellColumns(:, 100);
finalnbs.access_SOTI_2015SUMMER = rawCellColumns(:, 101);
finalnbs.access_SPOTIFY_FEED = rawCellColumns(:, 102);
finalnbs.access_TOUR_PLANNING = rawCellColumns(:, 103);
finalnbs.access_TRACK_PREVIEWS = rawCellColumns(:, 104);
finalnbs.access_UNIFIED = rawCellColumns(:, 105);
finalnbs.access_UNIFIED_ALERTS = rawCellColumns(:, 106);
finalnbs.access_UNIFIED_BENCHMARKS = rawCellColumns(:, 107);
finalnbs.access_UNIFIED_BOOKMARKS = rawCellColumns(:, 108);
finalnbs.access_UNIFIED_CONTENT = rawCellColumns(:, 109);
finalnbs.access_UNIFIED_CORRELATIONS = rawCellColumns(:, 110);
finalnbs.access_UNIFIED_DASHBOARD = rawCellColumns(:, 111);
finalnbs.access_UNIFIED_DEMOGRAPHICS = rawCellColumns(:, 112);
finalnbs.access_UNIFIED_EVENTS = rawCellColumns(:, 113);
finalnbs.access_UNIFIED_EXPORT_ADVANCED = rawCellColumns(:, 114);
finalnbs.access_UNIFIED_EXPORT_PDF = rawCellColumns(:, 115);
finalnbs.access_UNIFIED_EXPORT_XLS = rawCellColumns(:, 116);
finalnbs.access_UNIFIED_GOALS = rawCellColumns(:, 117);
finalnbs.access_UNIFIED_GRAPHS = rawCellColumns(:, 118);
finalnbs.access_UNIFIED_LOCATION_FILTERING = rawCellColumns(:, 119);
finalnbs.access_UNIFIED_MAPS = rawCellColumns(:, 120);
finalnbs.access_UNIFIED_PERFORMANCE_REPORT = rawCellColumns(:, 121);
finalnbs.access_UNIFIED_SCORE = rawCellColumns(:, 122);
finalnbs.access_UNIFIED_SETTINGS_SOURCES = rawCellColumns(:, 123);
finalnbs.access_UNIFIED_SETTINGS_TESTING = rawCellColumns(:, 124);
finalnbs.access_UNIFIED_TOUR = rawCellColumns(:, 125);
finalnbs.access_UNIVERSAL_SEARCH = rawCellColumns(:, 126);
finalnbs.accessed_unified = rawCellColumns(:, 127);
finalnbs.account = rawCellColumns(:, 128);
finalnbs.accountbilling_type = rawCellColumns(:, 129);
finalnbs.accountbraintree_active = rawCellColumns(:, 130);
finalnbs.accountbraintree_token = rawCellColumns(:, 131);
finalnbs.accountcreated_at = rawCellColumns(:, 132);
finalnbs.accountcreated_at_atEST = rawCellColumns(:, 133);
finalnbs.accountcreated_by = rawCellColumns(:, 134);
finalnbs.accountdiscount_rate = rawCellColumns(:, 135);
finalnbs.accountid = rawCellColumns(:, 136);
finalnbs.accountis_enterprise = rawCellColumns(:, 137);
finalnbs.accountname = rawCellColumns(:, 138);
finalnbs.accountprompt_cc = rawCellColumns(:, 139);
finalnbs.accountprompt_cc_atEST = rawCellColumns(:, 140);
finalnbs.accountuser_logins = rawCellColumns(:, 141);
finalnbs.account_id = rawCellColumns(:, 142);
finalnbs.account_name = rawCellColumns(:, 143);
finalnbs.administrator = rawCellColumns(:, 144);
finalnbs.app_id = rawCellColumns(:, 145);
finalnbs.artists_paying_for = rawCellColumns(:, 146);
finalnbs.bookmarks = rawCellColumns(:, 147);
finalnbs.bosslink = rawCellColumns(:, 148);
finalnbs.cancel_comments = rawCellColumns(:, 149);
finalnbs.cancel_reason = rawCellColumns(:, 150);
finalnbs.completed_setup = rawCellColumns(:, 151);
finalnbs.completed_setup_atEST = rawCellColumns(:, 152);
finalnbs.connected_fb = rawCellColumns(:, 153);
finalnbs.connected_ga = rawCellColumns(:, 154);
finalnbs.connected_itunes = rawCellColumns(:, 155);
finalnbs.created = rawCellColumns(:, 156);
finalnbs.created_atEST = rawCellColumns(:, 157);
finalnbs.created_at_epoch = rawCellColumns(:, 158);
finalnbs.dateRange_period = rawCellColumns(:, 159);
finalnbs.discount_rate = rawCellColumns(:, 160);
finalnbs.display = rawCellColumns(:, 161);
finalnbs.downgraded = rawCellColumns(:, 162);
finalnbs.email = rawCellColumns(:, 163);
finalnbs.email_alerts = rawCellColumns(:, 164);
finalnbs.email_day = rawCellColumns(:, 165);
finalnbs.email_news = rawCellColumns(:, 166);
finalnbs.environment = rawCellColumns(:, 167);
finalnbs.first_name = rawCellColumns(:, 168);
finalnbs.free_artists = rawCellColumns(:, 169);
finalnbs.has_bt = rawCellColumns(:, 170);
finalnbs.has_find = rawCellColumns(:, 171);
finalnbs.has_unified = rawCellColumns(:, 172);
finalnbs.hash = rawCellColumns(:, 173);
finalnbs.id = rawCellColumns(:, 174);
finalnbs.is_enterprise = rawCellColumns(:, 175);
finalnbs.is_free = rawCellColumns(:, 176);
finalnbs.is_kitchen_sink = rawCellColumns(:, 177);
finalnbs.is_paying = rawCellColumns(:, 178);
finalnbs.is_premier = rawCellColumns(:, 179);
finalnbs.is_upgraded = rawCellColumns(:, 180);
finalnbs.job_title = rawCellColumns(:, 181);
finalnbs.key_metrics_0 = rawCellColumns(:, 182);
finalnbs.key_metrics_1 = rawCellColumns(:, 183);
finalnbs.key_metrics_10 = rawCellColumns(:, 184);
finalnbs.key_metrics_11 = rawCellColumns(:, 185);
finalnbs.key_metrics_2 = rawCellColumns(:, 186);
finalnbs.key_metrics_3 = rawCellColumns(:, 187);
finalnbs.key_metrics_4 = rawCellColumns(:, 188);
finalnbs.key_metrics_5 = rawCellColumns(:, 189);
finalnbs.key_metrics_6 = rawCellColumns(:, 190);
finalnbs.key_metrics_7 = rawCellColumns(:, 191);
finalnbs.key_metrics_8 = rawCellColumns(:, 192);
finalnbs.key_metrics_9 = rawCellColumns(:, 193);
finalnbs.last_login = rawCellColumns(:, 194);
finalnbs.last_login_atEST = rawCellColumns(:, 195);
finalnbs.last_name = rawCellColumns(:, 196);
finalnbs.name = rawCellColumns(:, 197);
finalnbs.occupation = rawCellColumns(:, 198);
finalnbs.organization = rawCellColumns(:, 199);
finalnbs.packagebilling_cycle = rawCellColumns(:, 200);
finalnbs.packagebraintree_id = rawCellColumns(:, 201);
finalnbs.packagedescription = rawCellColumns(:, 202);
finalnbs.packagename = rawCellColumns(:, 203);
finalnbs.packageprice = rawCellColumns(:, 204);
finalnbs.packageuser_logins = rawCellColumns(:, 205);
finalnbs.picture = rawCellColumns(:, 206);
finalnbs.prompt_cc = rawCellColumns(:, 207);
finalnbs.prompt_cc_at = rawCellColumns(:, 208);
finalnbs.report_type_access_13_description = rawCellColumns(:, 209);
finalnbs.report_type_access_13_has_geo = rawCellColumns(:, 210);
finalnbs.report_type_access_13_has_time = rawCellColumns(:, 211);
finalnbs.report_type_access_13_icon = rawCellColumns(:, 212);
finalnbs.report_type_access_13_id = rawCellColumns(:, 213);
finalnbs.report_type_access_13_name = rawCellColumns(:, 214);
finalnbs.report_type_access_13_slug = rawCellColumns(:, 215);
finalnbs.report_type_access_13_weight = rawCellColumns(:, 216);
finalnbs.report_type_access_14_description = rawCellColumns(:, 217);
finalnbs.report_type_access_14_has_geo = rawCellColumns(:, 218);
finalnbs.report_type_access_14_has_time = rawCellColumns(:, 219);
finalnbs.report_type_access_14_icon = rawCellColumns(:, 220);
finalnbs.report_type_access_14_id = rawCellColumns(:, 221);
finalnbs.report_type_access_14_name = rawCellColumns(:, 222);
finalnbs.report_type_access_14_slug = rawCellColumns(:, 223);
finalnbs.report_type_access_14_weight = rawCellColumns(:, 224);
finalnbs.report_type_access_16_description = rawCellColumns(:, 225);
finalnbs.report_type_access_16_has_geo = rawCellColumns(:, 226);
finalnbs.report_type_access_16_has_time = rawCellColumns(:, 227);
finalnbs.report_type_access_16_icon = rawCellColumns(:, 228);
finalnbs.report_type_access_16_id = rawCellColumns(:, 229);
finalnbs.report_type_access_16_name = rawCellColumns(:, 230);
finalnbs.report_type_access_16_slug = rawCellColumns(:, 231);
finalnbs.report_type_access_16_weight = rawCellColumns(:, 232);
finalnbs.report_type_access_1_description = rawCellColumns(:, 233);
finalnbs.report_type_access_1_has_geo = rawCellColumns(:, 234);
finalnbs.report_type_access_1_has_time = rawCellColumns(:, 235);
finalnbs.report_type_access_1_icon = rawCellColumns(:, 236);
finalnbs.report_type_access_1_id = rawCellColumns(:, 237);
finalnbs.report_type_access_1_name = rawCellColumns(:, 238);
finalnbs.report_type_access_1_slug = rawCellColumns(:, 239);
finalnbs.report_type_access_1_weight = rawCellColumns(:, 240);
finalnbs.report_type_access_2_description = rawCellColumns(:, 241);
finalnbs.report_type_access_2_has_geo = rawCellColumns(:, 242);
finalnbs.report_type_access_2_has_time = rawCellColumns(:, 243);
finalnbs.report_type_access_2_icon = rawCellColumns(:, 244);
finalnbs.report_type_access_2_id = rawCellColumns(:, 245);
finalnbs.report_type_access_2_name = rawCellColumns(:, 246);
finalnbs.report_type_access_2_slug = rawCellColumns(:, 247);
finalnbs.report_type_access_2_weight = rawCellColumns(:, 248);
finalnbs.report_type_access_4_description = rawCellColumns(:, 249);
finalnbs.report_type_access_4_has_geo = rawCellColumns(:, 250);
finalnbs.report_type_access_4_has_time = rawCellColumns(:, 251);
finalnbs.report_type_access_4_icon = rawCellColumns(:, 252);
finalnbs.report_type_access_4_id = rawCellColumns(:, 253);
finalnbs.report_type_access_4_name = rawCellColumns(:, 254);
finalnbs.report_type_access_4_slug = rawCellColumns(:, 255);
finalnbs.report_type_access_4_weight = rawCellColumns(:, 256);
finalnbs.report_type_access_exports_description = rawCellColumns(:, 257);
finalnbs.report_type_access_exports_has_geo = rawCellColumns(:, 258);
finalnbs.report_type_access_exports_has_time = rawCellColumns(:, 259);
finalnbs.report_type_access_exports_icon = rawCellColumns(:, 260);
finalnbs.report_type_access_exports_id = rawCellColumns(:, 261);
finalnbs.report_type_access_exports_name = rawCellColumns(:, 262);
finalnbs.report_type_access_exports_slug = rawCellColumns(:, 263);
finalnbs.report_type_access_exports_weight = rawCellColumns(:, 264);
finalnbs.report_type_access_find_description = rawCellColumns(:, 265);
finalnbs.report_type_access_find_has_geo = rawCellColumns(:, 266);
finalnbs.report_type_access_find_has_time = rawCellColumns(:, 267);
finalnbs.report_type_access_find_icon = rawCellColumns(:, 268);
finalnbs.report_type_access_find_id = rawCellColumns(:, 269);
finalnbs.report_type_access_find_name = rawCellColumns(:, 270);
finalnbs.report_type_access_find_slug = rawCellColumns(:, 271);
finalnbs.report_type_access_find_weight = rawCellColumns(:, 272);
finalnbs.report_type_access_networks_description = rawCellColumns(:, 273);
finalnbs.report_type_access_networks_has_geo = rawCellColumns(:, 274);
finalnbs.report_type_access_networks_has_time = rawCellColumns(:, 275);
finalnbs.report_type_access_networks_icon = rawCellColumns(:, 276);
finalnbs.report_type_access_networks_id = rawCellColumns(:, 277);
finalnbs.report_type_access_networks_name = rawCellColumns(:, 278);
finalnbs.report_type_access_networks_slug = rawCellColumns(:, 279);
finalnbs.report_type_access_networks_weight = rawCellColumns(:, 280);
finalnbs.report_types_13_description = rawCellColumns(:, 281);
finalnbs.report_types_13_has_geo = rawCellColumns(:, 282);
finalnbs.report_types_13_has_time = rawCellColumns(:, 283);
finalnbs.report_types_13_icon = rawCellColumns(:, 284);
finalnbs.report_types_13_id = rawCellColumns(:, 285);
finalnbs.report_types_13_name = rawCellColumns(:, 286);
finalnbs.report_types_13_slug = rawCellColumns(:, 287);
finalnbs.report_types_13_weight = rawCellColumns(:, 288);
finalnbs.report_types_14_description = rawCellColumns(:, 289);
finalnbs.report_types_14_has_geo = rawCellColumns(:, 290);
finalnbs.report_types_14_has_time = rawCellColumns(:, 291);
finalnbs.report_types_14_icon = rawCellColumns(:, 292);
finalnbs.report_types_14_id = rawCellColumns(:, 293);
finalnbs.report_types_14_name = rawCellColumns(:, 294);
finalnbs.report_types_14_slug = rawCellColumns(:, 295);
finalnbs.report_types_14_weight = rawCellColumns(:, 296);
finalnbs.report_types_16_description = rawCellColumns(:, 297);
finalnbs.report_types_16_has_geo = rawCellColumns(:, 298);
finalnbs.report_types_16_has_time = rawCellColumns(:, 299);
finalnbs.report_types_16_icon = rawCellColumns(:, 300);
finalnbs.report_types_16_id = rawCellColumns(:, 301);
finalnbs.report_types_16_name = rawCellColumns(:, 302);
finalnbs.report_types_16_slug = rawCellColumns(:, 303);
finalnbs.report_types_16_weight = rawCellColumns(:, 304);
finalnbs.report_types_1_description = rawCellColumns(:, 305);
finalnbs.report_types_1_has_geo = rawCellColumns(:, 306);
finalnbs.report_types_1_has_time = rawCellColumns(:, 307);
finalnbs.report_types_1_icon = rawCellColumns(:, 308);
finalnbs.report_types_1_id = rawCellColumns(:, 309);
finalnbs.report_types_1_name = rawCellColumns(:, 310);
finalnbs.report_types_1_slug = rawCellColumns(:, 311);
finalnbs.report_types_1_weight = rawCellColumns(:, 312);
finalnbs.report_types_2_description = rawCellColumns(:, 313);
finalnbs.report_types_2_has_geo = rawCellColumns(:, 314);
finalnbs.report_types_2_has_time = rawCellColumns(:, 315);
finalnbs.report_types_2_icon = rawCellColumns(:, 316);
finalnbs.report_types_2_id = rawCellColumns(:, 317);
finalnbs.report_types_2_name = rawCellColumns(:, 318);
finalnbs.report_types_2_slug = rawCellColumns(:, 319);
finalnbs.report_types_2_weight = rawCellColumns(:, 320);
finalnbs.report_types_4_description = rawCellColumns(:, 321);
finalnbs.report_types_4_has_geo = rawCellColumns(:, 322);
finalnbs.report_types_4_has_time = rawCellColumns(:, 323);
finalnbs.report_types_4_icon = rawCellColumns(:, 324);
finalnbs.report_types_4_id = rawCellColumns(:, 325);
finalnbs.report_types_4_name = rawCellColumns(:, 326);
finalnbs.report_types_4_slug = rawCellColumns(:, 327);
finalnbs.report_types_4_weight = rawCellColumns(:, 328);
finalnbs.report_types_alerts_description = rawCellColumns(:, 329);
finalnbs.report_types_alerts_has_geo = rawCellColumns(:, 330);
finalnbs.report_types_alerts_has_time = rawCellColumns(:, 331);
finalnbs.report_types_alerts_icon = rawCellColumns(:, 332);
finalnbs.report_types_alerts_id = rawCellColumns(:, 333);
finalnbs.report_types_alerts_name = rawCellColumns(:, 334);
finalnbs.report_types_alerts_slug = rawCellColumns(:, 335);
finalnbs.report_types_alerts_weight = rawCellColumns(:, 336);
finalnbs.report_types_exports_description = rawCellColumns(:, 337);
finalnbs.report_types_exports_has_geo = rawCellColumns(:, 338);
finalnbs.report_types_exports_has_time = rawCellColumns(:, 339);
finalnbs.report_types_exports_icon = rawCellColumns(:, 340);
finalnbs.report_types_exports_id = rawCellColumns(:, 341);
finalnbs.report_types_exports_name = rawCellColumns(:, 342);
finalnbs.report_types_exports_slug = rawCellColumns(:, 343);
finalnbs.report_types_exports_weight = rawCellColumns(:, 344);
finalnbs.report_types_find_description = rawCellColumns(:, 345);
finalnbs.report_types_find_has_geo = rawCellColumns(:, 346);
finalnbs.report_types_find_has_time = rawCellColumns(:, 347);
finalnbs.report_types_find_icon = rawCellColumns(:, 348);
finalnbs.report_types_find_id = rawCellColumns(:, 349);
finalnbs.report_types_find_name = rawCellColumns(:, 350);
finalnbs.report_types_find_slug = rawCellColumns(:, 351);
finalnbs.report_types_find_weight = rawCellColumns(:, 352);
finalnbs.report_types_networks_description = rawCellColumns(:, 353);
finalnbs.report_types_networks_has_geo = rawCellColumns(:, 354);
finalnbs.report_types_networks_has_time = rawCellColumns(:, 355);
finalnbs.report_types_networks_icon = rawCellColumns(:, 356);
finalnbs.report_types_networks_id = rawCellColumns(:, 357);
finalnbs.report_types_networks_name = rawCellColumns(:, 358);
finalnbs.report_types_networks_slug = rawCellColumns(:, 359);
finalnbs.report_types_networks_weight = rawCellColumns(:, 360);
finalnbs.request_id = rawCellColumns(:, 361);
finalnbs.role = rawCellColumns(:, 362);
finalnbs.show_notices = rawCellColumns(:, 363);
finalnbs.signed_up = rawCellColumns(:, 364);
finalnbs.signed_up_atEST = rawCellColumns(:, 365);
finalnbs.subscribed_artists = rawCellColumns(:, 366);
finalnbs.tours_advanced_graphs_id = rawCellColumns(:, 367);
finalnbs.tours_advanced_graphs_seen = rawCellColumns(:, 368);
finalnbs.tours_artist_mgmt_intro_id = rawCellColumns(:, 369);
finalnbs.tours_artist_mgmt_intro_seen = rawCellColumns(:, 370);
finalnbs.tours_content_id = rawCellColumns(:, 371);
finalnbs.tours_content_seen = rawCellColumns(:, 372);
finalnbs.tours_dashboard_follow_entities_id = rawCellColumns(:, 373);
finalnbs.tours_dashboard_follow_entities_seen = rawCellColumns(:, 374);
finalnbs.tours_dashboard_id = rawCellColumns(:, 375);
finalnbs.tours_dashboard_seen = rawCellColumns(:, 376);
finalnbs.tours_enterprise_intro_id = rawCellColumns(:, 377);
finalnbs.tours_enterprise_intro_seen = rawCellColumns(:, 378);
finalnbs.tours_find_id = rawCellColumns(:, 379);
finalnbs.tours_find_seen = rawCellColumns(:, 380);
finalnbs.tours_geo_id = rawCellColumns(:, 381);
finalnbs.tours_geo_seen = rawCellColumns(:, 382);
finalnbs.tours_graphs_id = rawCellColumns(:, 383);
finalnbs.tours_graphs_seen = rawCellColumns(:, 384);
finalnbs.tours_overview_id = rawCellColumns(:, 385);
finalnbs.tours_overview_seen = rawCellColumns(:, 386);
finalnbs.tours_setup_id = rawCellColumns(:, 387);
finalnbs.tours_setup_seen = rawCellColumns(:, 388);
finalnbs.tours_sources_id = rawCellColumns(:, 389);
finalnbs.tours_sources_seen = rawCellColumns(:, 390);
finalnbs.tours_spotify_intro_id = rawCellColumns(:, 391);
finalnbs.tours_spotify_intro_seen = rawCellColumns(:, 392);
finalnbs.type = rawCellColumns(:, 393);
finalnbs.userid = rawCellColumns(:, 394);
finalnbs.user_id = rawCellColumns(:, 395);
finalnbs.Companyname = rawCellColumns(:, 396);
finalnbs.CompanyID = rawCellColumns(:, 397);
finalnbs.CompanylastseenEST = rawCellColumns(:, 398);
finalnbs.CompanycreatedatEST = rawCellColumns(:, 399);
finalnbs.Users = rawCellColumns(:, 400);
finalnbs.Companywebsessions = rawCellColumns(:, 401);
finalnbs.Plan = rawCellColumns(:, 402);
finalnbs.MonthlySpend = rawCellColumns(:, 403);
finalnbs.CompanySegment = rawCellColumns(:, 404);
finalnbs.Companytag = rawCellColumns(:, 405);
finalnbs.artists_paying_for1 = rawCellColumns(:, 406);
finalnbs.connected_fb1 = rawCellColumns(:, 407);
finalnbs.connected_ga1 = rawCellColumns(:, 408);
finalnbs.connected_itunes1 = rawCellColumns(:, 409);
finalnbs.discount_rate1 = rawCellColumns(:, 410);
finalnbs.downgraded1 = rawCellColumns(:, 411);
finalnbs.free_artists1 = rawCellColumns(:, 412);

% For code requiring serial dates (datenum) instead of datetime, uncomment
% the following line(s) below to return the imported dates as datenum(s).

% finalnbs.LastcontactedEST=datenum(finalnbs.LastcontactedEST);

%% Clear temporary variables
clearvars filename delimiter startRow formatSpec fileID dataArray ans raw col numericData rawData row regexstr result numbers invalidThousandsSeparator thousandsRegExp me dates blankDates anyBlankDates invalidDates anyInvalidDates rawNumericColumns rawCellColumns R;
%% Delete unwanted variables rowwise

pandoraCheckList = [finalnbs.Email finalnbs.email finalnbs.account finalnbs.account_name...
    finalnbs.occupation finalnbs.AccountName finalnbs.Email1 finalnbs.Companyname...
    finalnbs.Organization finalnbs.Occupation finalnbs.organization];
    
% Don't check account name for NBS because these are often "Next Big Sound
% Enterprise Trial".
nbsCheckList = [finalnbs.Email finalnbs.email...
    finalnbs.occupation, finalnbs.Email1, finalnbs.Companyname finalnbs.Organization...
    finalnbs.Occupation, finalnbs.organization];
% pandoraList = {'pandora','Pandora'};
% nbsList = {'nextbigsound','Next Big Sound'};
% This works only for exact text search
% pandoraidx = ismember(pandoraCheckList,pandoraList);
% nbsidx = ismember(nbsCheckList,nbsList);

% Other methods
% varsToKeep = setdiff(T.Properties.VariableNames, varsToRemove, 'stable');
% cellfun(@(x)(any(~cellfun(@isempty,regexp(x,teststrings)))),test)
% X = T{:, varsToKeep};  
% http://www.mathworks.com/matlabcentral/newsreader/view_thread/310652#846320
% http://uk.mathworks.com/matlabcentral/answers/43461-get-the-index-for-the-search-of-multiple-strings-within-an-array-of-strings
% http://www.mathworks.com/matlabcentral/fileexchange/24380-cstrainbp

pindx1 = strfind(pandoraCheckList, 'pandora');
pidx = find(not(cellfun('isempty', pindx1)));
pandoraCells = cellfun(@isempty,pindx1);
pandoraCellsIndex = all(pandoraCells, 2);
pindx2 = strfind(pandoraCheckList, 'Pandora');
pidx1 = find(not(cellfun('isempty', pindx2)));
pandoraCells2 = cellfun(@isempty,pindx2);
pandoraCellsIndex2 = all(pandoraCells2, 2);
nindx1 = strfind(nbsCheckList, 'Next Big Sound');
nidx1 = find(not(cellfun('isempty', nindx1)));
nCells = cellfun(@isempty,nindx1);
nCellsIndex = all(nCells, 2);
nindx2 = strfind(nbsCheckList, 'nextbigsound');
nidx2 = find(not(cellfun('isempty', nindx2)));
nCells2 = cellfun(@isempty,nindx2);
nCellsIndex2 = all(nCells2, 2);

% Combine and remove
nAll = [nCellsIndex2 nCellsIndex pandoraCellsIndex2 pandoraCellsIndex];
removeIndex = all(nAll, 2);

finalnbs(~removeIndex, : ) = [];

% Delete the row which contains NBS users (already deleted above, but worth
% check
nbsindex = strcmp(finalnbs.UserID, '50446');
finalnbs(nbsindex, : ) = [];

%% Clear variables

clearvars nAll nbsCheckList nbsindex nCells nCells2 nCellsIndex nCellsIndex2 nidx1 nidx2 nindx1 nindx2 pandoraCells pandoraCells2 pandoraCellsIndex pandoraCellsIndex2 pandoraCheckList pidx pidx1 pindx1 pindx2 removeIndex;

%% Delete column wise unnecessary variables
% Rename the company variables to make clearer
finalnbs.Properties.VariableNames{'Users'} = 'usersincompany';
finalnbs.Properties.VariableNames{'Plan'} = 'companyplan';
finalnbs.Properties.VariableNames{'MonthlySpend'} = 'companymonthlyspend';
finalnbs.Properties.VariableNames{'artists_paying_for1'} = 'companyartistspaidfor';

% Delete the columns which contain all blank variables
missingVals = ismissing(finalnbs);
badCols = all(missingVals, 1);
finalnbs = finalnbs(:, ~badCols);

% Create a new categorical for enterprise users
% http://uk.mathworks.com/matlabcentral/newsreader/view_thread/263142
isenterprise = strcmp(finalnbs.is_enterprise,'TRUE') | strcmp(finalnbs.accountis_enterprise,'Yes');
isenterprise = table(isenterprise);
finalnbs = [finalnbs isenterprise];
finalnbs.Properties.VariableNames{'isenterprise'} = 'isenterprise';
clearvars isenterprise;

% Create variables if the user has an account or not

nonaccountrows = cellfun(@isempty,finalnbs.account_id);
hasaccount = table(~nonaccountrows);
hasaccount.Properties.VariableNames{'Var1'} = 'hasaccount';
finalnbs = [finalnbs hasaccount];
finalnbs.account_id = [];

noncompanyrows = cellfun(@isempty,finalnbs.CompanyID);
hascompany = table(~noncompanyrows);
hascompany.Properties.VariableNames{'Var1'} = 'hascompany';
finalnbs = [finalnbs hascompany];
finalnbs.CompanyID = [];

clearvars hasaccount hascompany nonaccountrows noncompanyrows badCols missingVals;

%% Convert date based cell arrays to continuous explanatory variables
sincesignedup = table(days(datenum(2015,12,16,10,53,00)-datenum(datetime(finalnbs.SignedupEST, 'InputFormat', 'dd/MM/yyyy HH:mm'))));
sincelastseen = table(days(datenum(2015,12,16,10,53,00)-datenum(datetime(finalnbs.LastseenEST, 'InputFormat', 'dd/MM/yyyy HH:mm'))));
sincelastcontacted = table(days(datenum(2015,12,16,10,53,00)-datenum(datetime(finalnbs.LastcontactedEST, 'InputFormat', 'dd/MM/yyyy HH:mm'))));
sincelastheardfrom = table(days(datenum(2015,12,16,10,53,00)-datenum(datetime(finalnbs.LastheardfromEST, 'InputFormat', 'dd/MM/yyyy HH:mm'))));
sincefirstseen = table(days(datenum(2015,12,16,10,53,00)-datenum(datetime(finalnbs.FirstSeenEST, 'InputFormat', 'dd/MM/yyyy HH:mm'))));
sincecompanylastseen = table(days(datenum(2015,12,16,10,53,00)-datenum(datetime(finalnbs.CompanylastseenEST, 'InputFormat', 'dd/MM/yyyy HH:mm'))));
sincecompanycreated = table(days(datenum(2015,12,16,10,53,00)-datenum(datetime(finalnbs.CompanycreatedatEST, 'InputFormat', 'dd/MM/yyyy HH:mm'))));
sinceaccountcreated = table(days(datenum(2015,12,16,10,53,00)-datenum(datetime(finalnbs.accountcreated_at_atEST, 'InputFormat', 'dd/MM/yyyy HH:mm'))));
sincecompletedsetup = table(days(datenum(2015,12,16,10,53,00)-datenum(datetime(finalnbs.completed_setup_atEST, 'InputFormat', 'dd/MM/yyyy HH:mm'))));
sinceusercreated = table(days(datenum(2015,12,16,10,53,00)-datenum(datetime(finalnbs.Created, 'InputFormat', 'dd/MM/yyyy HH:mm'))));
% last login at '1430750966' and 'Sep 04, 2012'
% http://uk.mathworks.com/matlabcentral/answers/7631-multiple-date-and-time-formats-in-txt-files

neverloggedin = table(strcmp(finalnbs.LastseenEST, '31/12/1969 19:00'));

sincecompletedsetup.Properties.VariableNames{'Var1'} = 'sincecompletedsetup';
sinceusercreated.Properties.VariableNames{'Var1'} = 'sinceusercreated';
sinceaccountcreated.Properties.VariableNames{'Var1'} = 'sinceaccountcreated';
sincesignedup.Properties.VariableNames{'Var1'} = 'sincesignedup';
sincelastseen.Properties.VariableNames{'Var1'} = 'sincelastseen';
sincelastcontacted.Properties.VariableNames{'Var1'} = 'sincelastcontacted';
sincelastheardfrom.Properties.VariableNames{'Var1'} = 'sincelastheardfrom';
sincefirstseen.Properties.VariableNames{'Var1'} = 'sincefirstseen';
sincecompanylastseen.Properties.VariableNames{'Var1'} = 'sincecompanylastseen';
sincecompanycreated.Properties.VariableNames{'Var1'} = 'sincecompanycreated';
neverloggedin.Properties.VariableNames{'Var1'} = 'neverloggedin';

finalnbs = [finalnbs sincefirstseen sincelastcontacted sincelastheardfrom...
    sincelastseen sincesignedup sincecompanylastseen sincecompanycreated...
    sinceaccountcreated sincecompletedsetup sinceusercreated neverloggedin];

clearvars sinceaccountcreated sincecompanycreated sincecompanylastseen sincecompletedsetup sincefirstseen sincelastcontacted sincelastheardfrom sincelastseen sincesignedup sinceusercreated neverloggedin;

%% Keep the variables that decided by the client as being relevant only

%Timezone is a proxy for country, and has the least categories, but will
%keep both. Definitely removing city and region etc.
% It seems like city, region and country are extremely large in terms of
% categories, sometimes beyond 4000. So, I am going to remove these. Its
% also true that these create explanatory variable bias (the same city will
% appear matched to the same country). We only need one of these (I will
% take country).

cleannbs = table(...
    finalnbs.Websessions,...
    finalnbs.neverloggedin,...
    finalnbs.Browser,...
    finalnbs.Country,...
    finalnbs.Timezone,...
    finalnbs.KloutScore, ...
    finalnbs.UnsubscribedfromEmails,...
    finalnbs.accountbilling_type,...
    finalnbs.accountbraintree_active,...
    finalnbs.artists_paying_for,...
    finalnbs.bookmarks,finalnbs.connected_fb,finalnbs.connected_ga,...
    finalnbs.connected_itunes,finalnbs.email_alerts,...
    finalnbs.email_day, finalnbs.email_news, finalnbs.free_artists,...
    finalnbs.has_bt, finalnbs.has_find, finalnbs.has_unified,...
   finalnbs.is_free,...
   finalnbs.is_kitchen_sink,...
        finalnbs.is_paying,...
        finalnbs.is_premier,...
        finalnbs.is_upgraded,...
        finalnbs.subscribed_artists,...
        finalnbs.sincefirstseen,...
        finalnbs.sincelastcontacted,...
        finalnbs.sincelastheardfrom,...
        finalnbs.sincelastseen,...
        finalnbs.sincesignedup,...
        finalnbs.sincecompanylastseen,...
        finalnbs.sincecompanycreated,...
        finalnbs.sinceaccountcreated,...
        finalnbs.sincecompletedsetup,...
        finalnbs.sinceusercreated,...
        finalnbs.isenterprise,...
        finalnbs.hasaccount,...
        finalnbs.hascompany,...
        finalnbs.occupation);
cleannbs.Properties.VariableNames ={
        'Websessions'...
        'NeverLoggedIn'...
        'Browser'...
        'Country'...
        'Timezone'...
        'KloutScore'...
        'UnsubscribedfromEmails'...
        'accountbilling_type'...
        'accountbraintree_active'...
        'artists_paying_for'...
        'bookmarks'...
        'connected_fb'...
        'connected_ga'...
        'connected_itunes'...
        'email_alerts'...
        'email_day'...
        'email_news'...
        'free_artists'...
        'has_bt'...
        'has_find'...
        'has_unified'...
        'is_free'...
        'is_kitchen_sink'...
        'is_paying'...
        'is_premier'...
        'is_upgraded'...
        'subscribed_artists'...
        'sincefirstseen'...
        'sincelastcontacted'...
        'sincelastheardfrom'...
        'sincelastseen'...
        'sincesignedup'...
        'sincecompanylastseen'...
        'sincecompanycreated'...
        'sinceaccountcreated'...
        'sincecompletedsetup'...
        'sinceusercreated'...
        'isenterprise'...
        'hasaccount'...
        'hascompany'...
        'occupation'...
    };

% varsToKeep = {
%         'Websessions',...
%         'NeverLoggedIn',...
%         'Browser',...
%         'Country',...
%         'Timezone',...
%         'KloutScore',...
%         'UnsubscribedfromEmails',...
%         'accountbilling_type',...
%         'accountbraintree_active',...
%         'artists_paying_for',...
%         'bookmarks',...
%         'connected_fb',...
%         'connected_ga',...
%         'connected_itunes',...
%         'email_alerts',...
%         'email_day',...
%         'email_news',...
%         'free_artists',...
%         'has_bt',...
%         'has_find',...
%         'has_unified',...
%         'is_free',...
%         'is_kitchen_sink',...
%         'is_paying',...
%         'is_premier',...
%         'is_upgraded',...
%         'subscribed_artists',...
%         'sincefirstseen',...
%         'sincelastcontacted',...
%         'sincelastheardfrom',...
%         'sincelastseen',...
%         'sincesignedup',...
%         'sincecompanylastseen',...
%         'sincecompanycreated',...
%         'sinceaccountcreated',...
%         'sincecompletedsetup',...
%         'sinceusercreated',...
%         'isenterprise',...
%         'hasaccount',...
%         'hascompany',...
%         'occupation'...
%     };

%% Convert categorical variables and logical variables

% Define the categorical variables

catVars = {'Country', 'Timezone', 'Browser',... 
  'email_day', 'occupation', 'accountbilling_type'};

newTable = varfun(@categorical,cleannbs,'inputvariables',catVars);
cleannbs = [cleannbs(:,~ismember(cleannbs.Properties.VariableNames,catVars))...
    newTable];

clearvars newTable;

%http://uk.mathworks.com/matlabcentral/answers/123458-converting-multiple-table-variables-from-string-to-categorical-data
% 
cleannbs.KloutScore = str2double(cleannbs.KloutScore);
cleannbs.artists_paying_for = str2double(cleannbs.artists_paying_for);
cleannbs.bookmarks = str2double(cleannbs.bookmarks);
cleannbs.connected_ga = str2double(cleannbs.connected_ga);
cleannbs.connected_fb = str2double(cleannbs.connected_fb);
cleannbs.connected_itunes = str2double(cleannbs.connected_itunes);
cleannbs.free_artists = str2double(cleannbs.free_artists);
cleannbs.subscribed_artists = str2double(cleannbs.subscribed_artists);

% http://stackoverflow.com/questions/2624016/replace-empty-cells-with-logical-0s-before-cell2mat-in-matlab
% There are logical variables, but in my case, those which are blank are
% not 0, so I am making these categorical also.

logicalVars = {'UnsubscribedfromEmails','has_bt', 'has_find',... 
    'is_kitchen_sink', 'is_free', ...
    'is_paying', 'is_premier','accountbraintree_active', 'is_upgraded', 'hasaccount',...
    'hascompany', 'isenterprise','email_alerts','email_news','has_unified','NeverLoggedIn'};

newTable = varfun(@categorical,cleannbs,'InputVariables',logicalVars);
cleannbs = [cleannbs(:,~ismember(cleannbs.Properties.VariableNames,logicalVars))...
    newTable];

clearvars newTable;

% Convert duration arrays to doubles

cleannbs.sincelastcontacted = days(cleannbs.sincelastcontacted);
cleannbs.sincelastheardfrom = days(cleannbs.sincelastheardfrom);
cleannbs.sincefirstseen = days(cleannbs.sincefirstseen);
cleannbs.sincesignedup = days(cleannbs.sincesignedup);
cleannbs.sincecompanylastseen = days(cleannbs.sincecompanylastseen);
cleannbs.sincecompletedsetup = days(cleannbs.sincecompletedsetup);
cleannbs.sinceusercreated = days(cleannbs.sinceusercreated);
cleannbs.sinceaccountcreated = days(cleannbs.sinceaccountcreated);
cleannbs.sincecompanycreated = days(cleannbs.sincecompanycreated);
cleannbs.sincelastseen = days(cleannbs.sincelastseen);

clearvars finalnbs;

%% Change the labels of the dataset

labels1 = cleannbs.Properties.VariableNames(1:19);
labels = cleannbs.Properties.VariableNames(20:end);
% Remove prefix and underscores from the labels.
labels = cellfun(@(s) strrep(s(12:end), '_', ''), labels, ...
                 'UniformOutput', false);
labels = [labels1 labels];
cleannbs.Properties.VariableNames = labels;

clearvars labels1 labels;

%% Set up default figure options for nice published charts.
figOpts = {'Units', 'Normalized', 'Position', 0.125*[1, 1, 6, 6]};

%% Show a chart of the missing data

missingVals = ismissing(cleannbs); % Large NaNs, all converted to numbers

% Visualise the missing and present values.
figure(figOpts{:})
imagesc(missingVals)
colormap([0, 0, 1; 1, 1, 0]) % Use blue and yellow in the heat map.
axis off
colorbar
title('Missing (1) and Present (0) Values')

% Count missing values.
% In each variable:
nMissingByVar = sum(missingVals, 1);
% In each observation:
nMissingByObs = sum(missingVals, 2);
% Overall:
nMissing = sum(missingVals(:));
% As a percentage of all values:
missingPC = 100*nMissing/numel(cleannbs);
% How many variables are totally missing?
missingVarsIdx = all(missingVals, 1);
nVarsMissing = sum(missingVarsIdx);
display(nVarsMissing)
% Which ones?
missingVars = cleannbs.Properties.VariableNames(missingVarsIdx);
display(missingVars)

% Chart the results.
figure(figOpts{:})
subplot(2, 1, 1)
bar(nMissingByVar, 'FaceColor', [1, 0.5, 0], 'EdgeColor', 0.8*ones(1, 3))
xlabel('Variable Index')
ylabel('Missing Value Count')
title('Missing Values by Variable')
grid
subplot(2, 1, 2)
barh(nMissingByObs, 'FaceColor', 'k')
xlabel('Missing Value Count')
ylabel('Observation Index')
title('Missing Values by Observation')
grid

%% Clear variables

clearvars missingVals missingVars missingVarsIdx nMissing nMissingByObs...
    nMissingByVar nVarsMissing missingPC;

%% Remove rows and columns again

% Remove users with less than 6 months of data (since last signed up).
insufficientTimeData = cleannbs.sincesignedup<(30*6);
cleannbs = cleannbs(~insufficientTimeData,:);
clearvars insufficientTimeData;

% Reduce the rows and the columns with sparse data
missingVals = ismissing(cleannbs);
badRows = sum(missingVals, 2)/width(cleannbs)>0.50;
% badRows2 = sum(missingVals, 2)/width(cleannbs)>0.80;
% badRows3 = sum(missingVals, 2)>0;

badCols = sum(missingVals, 1)/height(cleannbs)>0.50;
% badCols2 = sum(missingVals, 1)/height(cleannbs)>0.80;
% badCols3 = sum(missingVals, 1)>0;
cleannbs = cleannbs(~badRows, ~badCols);

%Create a flag for users who have never logged in or don't have any web
%sessions
webSessions0 = cleannbs.Websessions==0;
neverLoggedIn = cleannbs.NeverLoggedIn == 'true'; 
deadusers = table(neverLoggedIn & webSessions0);
cleannbs = [cleannbs  deadusers];
cleannbs.Properties.VariableNames{'Var1'} = 'deadusers';

% Create a proxy for activity via a "sessions per month".
sessionspermonth = table(cleannbs.Websessions./(cleannbs.sincesignedup/30));
cleannbs = [cleannbs sessionspermonth];
cleannbs.Properties.VariableNames{'Var1'} = 'sessionspermonth';

% Plot web sessions against the days since the user was signed up
figure(figOpts{:});
scatterhist(cleannbs.sincesignedup,cleannbs.Websessions,'Group',cleannbs.deadusers);
legend('Alive', 'Dead')     
grid
xlabel('Days Since Signed Up')
ylabel('Web Sessions')
title('Web Sessions over Time')
set(gca,'xscale','log');
h = lsline;
h(1).Color = [0, 0.447, 0.741];
h(2).Color = [0.85, 0.325, 0.098];
set(h, 'LineWidth', 1)

clearvars sessionspermonth deadusers badRows badCols h missingVals neverLoggedIn neverLoggedIn;

%% Now I split my Y variable into highly active and inactive (2 categories)

activity = cleannbs.sessionspermonth;

% The previous definition of gross sessions was not adjusted for time
% signed up. 
p25tile = quantile(activity,0.25);
medianactivity = nanmedian(activity);
p95tile = quantile(activity,0.95);
% As we can see, the 25th percentile of sessions per month is 0, and the
% median is 0.0156.
monthvsraw = [cleannbs.Websessions cleannbs.sessionspermonth];
monthvsraw = monthvsraw(monthvsraw(:,1)>50,:);
% As we can see, the normalised web sessions roughly corresponds to being
% above 0.79 times a month

activeEdges = [0, p95tile, Inf];
activeCats = {'Inactive', ...
           'Highly Active'};
response = table(discretize(activity, activeEdges, 'categorical', activeCats));
summary(response)
cleannbs = [cleannbs response];
cleannbs.Properties.VariableNames{'Var1'} = 'activity';

% I assume that we only need to have one of the "time" based variables, and
% this will just allow us to compute if someone is classified as "active"
% or not active as this will be correlated with the normalised activity
% rate.

cleannbs.sincelastseen = [];
cleannbs.sincefirstseen = [];
cleannbs.sincelastcontacted= [];
cleannbs.sincesignedup= [];

% % Remove all columns with more than 1000 missing values;
% sum(ismissing(cleannbs),1);
% cleannbs = cleannbs(:,~missingVals);

% Remove the final missing values
missingVals = ismissing(cleannbs);
badRows = sum(missingVals, 2)>0;
finalnbs = cleannbs(~badRows, :);
finalnbs.deadusers = categorical(finalnbs.deadusers);

%% Plot the number of categories per categorical variable
% A lot of the predictors have several categories. I want to plot these.
catVars = find(varfun(@iscategorical,finalnbs(:,1:end),...
    'OutputFormat','uniform'));% Indices of categorical variables
countCats = @(var)numel(categories(nominal(var)));
numCat = varfun(@(var)countCats(var),finalnbs(:,catVars),...
    'OutputFormat','uniform');%This is the number of categories per categorical variable
figure;
barh(numCat); %#Horizontal bar chart
h = gca;
varNames = finalnbs.Properties.VariableNames;
title 'Categories per categorical predictor';
h.YTickLabel = varNames(catVars);
h.TickDir = 'out';
h.FontSize = 8;
ylabel 'Predictor';
xlabel 'Number of categories'
% YData = get(m,'XData'); 
% set(gca,'Ytick',linspace(YData(1),YData(end)-1));
% h.YTick = 1:numel(varNames) - 1;
clearvars m h countCats varNames; 
%% Convert all categories to numeric double values
convertednbs = finalnbs;
% First, convert all categorical variables to their double equivalent.
cat = varfun(@iscategorical,convertednbs(:,1:end),...
    'OutputFormat','uniform'); % Logical flag for categorical variables
catVars = find(cat);           % Indices of categorical variables
for k = 1:numel(catVars)
    convertednbs.(catVars(k)) = double(convertednbs.(catVars(k)));
end % for

clearvars k;
clearvars cat;
clearvars numCat;
%% Summarise the variables we have to play with
summary(convertednbs);
%% Split the variables
continuousnbs = convertednbs(:,[1:8,27]);
categoricalnbs = convertednbs(:,[9:26 28]);
%% Plot scatter plot matrix between all continuous variables by group
% Multiple pairwise comparisons.
continuousnbsarray = table2array(continuousnbs);
figure(figOpts{:})
plotmatrix(continuousnbsarray)
title('Pairwise Joint Distributions for Continuous Vars')

% Multiple pairwise comparisons, by a categorical grouping variable.
% Stratify the body measurement comparisons by male/female.
figure(figOpts{:})
gplotmatrix(continuousnbsarray, [], convertednbs.activity)
title('Pairwise Joint Distributions for Continuous Vars, by Activity Type')
%House cleaning
clearvars medianactivity missingVals monthvsraw p25tile p95tile response...
    webSessions0 catVars badRows activity activeEdges activeCats;
%% Standardise all variables, including the categorical variables
f1 = @(V) zscore(V);
f2 = @(V) (V - median(V))/iqr(V);
f3 = @(V) (V - min(V))/range(V); % Transforms data into the interval [0,1].

zscorenbs = varfun(f1, convertednbs(:, 1:end));
medscorenbs = varfun(f2, convertednbs(:, 1:end));
rngscorenbs = varfun(f3, convertednbs(:, 1:end));

labels = zscorenbs.Properties.VariableNames(1:end);
labels = cellfun(@(s) strrep(s(4:end), '_', ''), labels, ...
                 'UniformOutput', false);
zscorenbs.Properties.VariableNames = labels;
medscorenbs.Properties.VariableNames = labels;
rngscorenbs.Properties.VariableNames = labels;

clearvars f1 f2 f3 labels;

%% Remove unnecessary coefficients by correlation coefficients between variables
% varIndex = [9,2:8];
convertednbsarray = table2array(convertednbs);
varIndex = [2,3:26];
correlatedDoubles = corr(convertednbsarray(:,varIndex), 'rows', 'complete',...
    'type','Spearman'); 
% Spearman correlation is a bit more powerful. I am only taking the
% correlated double variables. Some features only exist when users have an
% account so I need to account for this.

% Keep the correlation for non-zero rows only, zeros occur frequently.
% Zeros there because most of the values. Logic makes sense.

figure(figOpts{:})
imagesc(correlatedDoubles, [-1, 1]) % Peg the colour limits to +/-1.
colormap(jet(64))
labels = convertednbs.Properties.VariableNames(varIndex);
ax = gca;
ax.TickLabelInterpreter = 'none'; % Prevent automatic sub/superscripting.
ax.XTick = 1:numel(labels);
ax.YTick = 1:numel(labels);
ax.XTickLabel = labels;
ax.YTickLabel = labels;
ax.XTickLabelRotation = 45;
colorbar
title('Next Big Sound Variables Correlation Chart')
% Identify pairs of variables with a high correlation. This is easy with
% logical indexing. We can use the SPY function to highlight the pairs of
% variables with a strong correlation.
D = correlatedDoubles - eye(size(correlatedDoubles)); % Exclude the diagonal.
highCorr = D > 0.6;
hold on
spy(highCorr, 'k.', 30)

clearvars highCorr labels varIndex D correlatedDoubles ax;

%% Perform PCA to remove unnecessary variables
%PCA provides us with a lower dimension surface on which to project the
% data, and needs to do mean normalisation and feature scaling. 
% Points have to move huge distance to get onto the new line. Find k vectors on which
% to project the data, where k<n, where n is the dimensions.
%Average projection error divided by the total variance should be less than
%1%, so that 99% of the variance is retained of the data. The total
%variance is the sum of the modulus of the xs squared, x distance between x
%and each other.Allows you to loop through values of k - gives you all the
%values of S up to n, so you can calculate the sum ratio and just report
%that number via a loop.

pcaX = zscorenbs{1:5000, [2:26,28]};
labels = zscorenbs.Properties.VariableNames([2:26,28]);
% We obtain the % of the variance explained by each component, the
% principal component scores, and the eigvals are the principal component
% variances in themselves.
[coeffs, scores, eigvals, t2, varExp] = pca(pcaX);
% Quickly visualise the raw data, variables and the first 2 or 3 principal
% components. % Normalise for time all the variables.
figure(figOpts{:})
biplot(coeffs(:, 1:3), 'Scores', scores(:, 1:3), 'VarLabels', labels)
title('Data and Variables in the first 3 Principal Components')

% We can create a heat map to visualise the principal component
% coefficients.
figure(figOpts{:})
imagesc(coeffs, [-1, 1]) 
% Each coefficient lies between -1 and +1 since coeffs is an orthogonal
% matrix. The eigenvectors of the covariance matrix are computed.
% http://stats.stackexchange.com/questions/222/what-are-principal-component-scores
colormap(jet(64))
colorbar
set(gca, 'XTick', 1:numel(labels), ...
         'YTick', 1:numel(labels), ...
         'XTickLabel', 1:numel(labels), ...
         'YTickLabel', labels)
xlabel('Principal Component')
title('Principal Component Coefficients')

% Create a ribbon visualisation of the same coefficients.
figure(figOpts{:})
ribbon(coeffs)
colormap(jet(64))
set(gca, 'XTick', 1:numel(labels), ...
         'YTick', 1:numel(labels), ...
         'YTickLabel', numel(labels):-1:1, ...
         'XTickLabel', labels(end:-1:1), ...
         'XTickLabelRotation', -45)
ylabel('Principal Component')
title('Principal Component Coefficients, Ribbon Chart')

% Visualise explained variances.
figure(figOpts{:})
subplot(2, 1, 1)
plot(eigvals, 'bo-')
xlabel('Principal Component')
ylabel('Eigenvalue')
title('PCA Eigenvalues')

subplot(2, 1, 2)
pareto(eigvals)
xlabel('Principal Component')
ylabel('Eigenvalue')
title('Scree (Pareto) Chart of PCA Eigenvalues')

% Broken stick method computes which PCs account for more variance 
% than would be expected by chance alone.
p = numel(eigvals);%The number of eigvals
w = 1./(1:p).';
g = cumsum(w, 'reverse')/p;
propvar = eigvals/sum(eigvals);
pcsToKeep = find(propvar >= g);
display(pcsToKeep)
% We see that the broken stick method recommends that the following
% principal components are kept.
% 1
% We can also use the function ROTATEFACTORS to align the principal
% components with the original variables as much as possible.
A = rotatefactors(coeffs);
figure(figOpts{:})
biplot(A(:, 1:3), 'VarLabels', labels)
title('Rotated Coordinate System After PCA')
% We see that 3 variables carry the most information content among the
% variables selected.
% http://www.mathworks.com/matlabcentral/answers/86795-how-to-index-or-retrive-the-original-information-after-pca
% http://matlabdatamining.blogspot.co.uk/2010/02/principal-components-analysis.html

clearvars propvar scores t2 g varExp varsToKeep w pcaX p eigvals coeffs A labels...
    originalSelection;

%% Create dummy variables for the categorical predictors instead of ordinals

%categoricalnbs is the number converted version for all the categorical
%variables. Some columns in that table have categories 1-200, some just
%have categories 1 to 20.
categoricalnbsarray = table2array(categoricalnbs);
% categoricalnbsarray = table2array(finalnbs(:,[9:26,28]));
%finalnbs keeps the actual category names, which I thought could help with
%generating the column labels for the dummyvars, but using that line
%doesn't help.

[~, ~, ugroupA] = unique(categoricalnbsarray(:,2));
dummyvars=dummyvar(ugroupA);
dummyvars = array2table(dummyvars);

% X01 = bsxfun(@rdivide, bsxfun(@minus, X, mean(X)), range(X));
% Make sure X is already a cell array
% with {}
clearvars ugroupA;

%% Do a logistic regression with bookmarks and free artists
figure(figOpts{:})
h = gscatter(finalnbs.free_artists,finalnbs.bookmarks,finalnbs.activity);
set(h, 'Markersize', 15)
xlabel('Free Artists')
ylabel('Bookmarks')
grid
hold on

% Use fitglm to fit a general linear model

%http://uk.mathworks.com/help/stats/fitglm.html

simpleModel = fitglm(finalnbs.free_artists, finalnbs.bookmarks);

sampleVals = linspace(min(finalnbs.bookmarks), max(finalnbs.bookmarks), 5000).';
fitVals = predict(simpleModel, sampleVals);
% Add the model to the chart.
plot(sampleVals, fitVals, 'k.-', 'LineWidth', 2)

clearvars h sampleVals fitVals;

%Bookmarks seems to be a good predictor. Let's try that

%% Fit a logistic ordinal model using only free_artists and bookmarks

ordinalresponse = ordinal(convertednbs.activity,{'Inactive','Highly Active'});

[B,dev,stats] = mnrfit([convertednbs.free_artists convertednbs.bookmarks]...
    ,ordinalresponse,'model','ordinal');
pvalues = stats.p;
interpretation = [B(1:2)'; repmat(B(3:end),1,2)];

% http://uk.mathworks.com/matlabcentral/answers/261517-overall-interpretation-of-multinomial-ordinal-logistic-regression-model-and-how-to-improve-with-mor

%% Do a logistic regression that takes care of the categorical variables automatically

%http://uk.mathworks.com/help/stats/stepwiseglm.html
% stepwiseModel1 = stepwiseglm(predictormatrix,numresponse);
% stepwiseModel2 = stepwiseglm(predictormatrix, numresponse,'constant','upper','linear');
% The below didn't work. Also, couldn't assume was a Poisson distribution
% stepwise3 = stepwiseglm(predictormatrix, response,'constant','upper','linear','Link','logit');

%% Create a raw dataset that contains equal amounts of active and inactive users

catresponse = finalnbs.activity;

sortedfinalnbs = sortrows(finalnbs,'activity');
sortedconvertednbs = sortrows(convertednbs,'activity');
sortedzscorenbs = sortrows(zscorenbs,'activity');
balancedfinalnbs =  sortedfinalnbs(end-sum(catresponse=='Highly Active')*2:end,:);
balancedconvertednbs = sortedconvertednbs(end-sum(catresponse=='Highly Active')*2:end,:);
balancedzscorenbs = sortedzscorenbs(end-sum(catresponse=='Highly Active')*2:end,:);


predictortable = balancedzscorenbs(:,2:24);
predictormatrix = table2array(predictortable);
catresponse = balancedfinalnbs.activity;
numresponse = balancedconvertednbs.activity;
contpredictormatrix = balancedfinalnbs(:,2:8);
contpredictormatrix = table2array(contpredictormatrix);
contresponse = balancedfinalnbs.sessionspermonth;
%% Training and validation.
% Create a cross-validation partition object.
% This defines a random partition of the data with 70% of the data to be
% used for training and 30% of the data reserved for validation (the
% holdout sample).

rng default
c = cvpartition(catresponse, 'HoldOut', 0.3);

% Extract the indices of the training and test sets.
trainIdx = training(c);
testIdx = test(c);
% Create the training and test data sets.
XTrain = predictormatrix(trainIdx, :);
XTest = predictormatrix(testIdx, :);
yTrain = catresponse(trainIdx);
yTest = catresponse(testIdx);
XTrainLasso = contpredictormatrix(trainIdx, :);
XTestLasso = contpredictormatrix(testIdx, :);
yTrainLasso= contresponse(trainIdx);
yTestLasso = contresponse(testIdx);
%% Create a base case prediction, which is that every single user is inactive (1)

% If my models do better than this, this is good.

dumPred = categorical(cellstr(repmat('Inactive', size(yTest,1), 1)));

errs = dumPred~=nominal(yTest);
testErrRateDum = 100*sum(errs)/numel(errs);
display(testErrRateDum)

% cvModel = crossval(dumPred); % 10-fold is default 
% cvErrorDumPred = 100*kfoldLoss(cvModel);
% display(cvErrorDumPred)

clearvars labels originalSelection bookmarkspredictor simpleModel errs;

%% Nearest neighbour classification.
% Idea: start with a simple classifier.
% * The kNN algorithm ("5 nearest neighbours") uses the majority features from
% the k closest points to determine the class of the unlabelled data.
% * The classification algorithm is as follows: determine the k nearest
% points in the labelled data (this is provided at the training stage).
% Then, retrieve the classes of these k points. Assign the new observation
% the class that has the smallest expected misclassification cost.

% Fit and predict the model on the training set
knnModel = fitcknn(XTrain, yTrain, 'NumNeighbors', 5);
knnPred = predict(knnModel, XTest);

% Investigate overall error rate in the test set.
errs = knnPred ~= yTest;
testErrRateKNN = 100*sum(errs)/numel(errs);
display(testErrRateKNN)

% Perform 10-fold cross validation.
% cvModel = crossval(knnModel); % 10-fold is default 
% cvErrorKNN = 100*kfoldLoss(cvModel);
% display(cvErrorKNN)
% Alternatively, use LOSS:
% testErrRate = 100*loss(knnModel, XTest, yTest);

% View confusion matrix (summary of known groups vs. predicted groups).
% A diagonal confusion matrix represents perfect classification. 
C = confusionmat(yTest, knnPred);
figure(figOpts{:})
imagesc(C)
colorbar
colormap('cool')
[Xgrid, Ygrid] = meshgrid(1:size(C, 1));
Ctext = num2str(C(:));
text(Xgrid(:), Ygrid(:), Ctext)
labels = categories(catresponse);
set(gca, 'XTick', 1:size(C, 1), 'XTickLabel', labels, ...
         'YTick', 1:size(C, 1), 'YTickLabel', labels, ...
         'XTickLabelRotation', 30, ...
         'TickLabelInterpreter', 'none')
xlabel('Predicted Class')
ylabel('Known Class')
title('KNN Confusion Matrix')


%% Naive Bayes classification.
% * The Naive Bayes classifier is popular as it is easy to construct and
%   interpret.
% * It is based on Bayes' theorem. During training, the model estimate the
%   parameters of a Normal distribution, assuming independent features 
%   within each class. 
% * The posterior probability of each sample belonging to each class is
%   determined. The sample is then classified according to the largest
%   posterior probability.
% * "Naive" refers to the assumption of independence in classes.
% * Normal distributions are used by default. We can also use "kernel"
%   without making distributional assumptions, at the cost of longer
%   training.

%% Examining distributions.
% Before fitting a Naive Bayes classifier, we examine the probability
% distribution in different classes of a measurement variable.
v1 = predictormatrix(:, 1); % Artists paying for
v2 = predictormatrix(:, 2); % Bookmarks
v3 = predictormatrix(:, 3); % Connected FB
v4 = predictormatrix(:, 4); % Connected GA
v5 = predictormatrix(:, 5); % Connected iTunes
v6 = predictormatrix(:, 6); % Free Artists
v7 = predictormatrix(:, 7); % Subscribed Artists
cats = categories(catresponse);
figure(figOpts{:})
for k = numel(cats):-1:1
    subplot(1, numel(cats), k)
    normplot(v1(catresponse == cats{k}))
    jbResults(k) = jbtest(v1(catresponse == cats{k}));
    title(cats{k})
end % for
display(jbResults)

figure(figOpts{:})
for k = numel(cats):-1:1
    subplot(1, numel(cats), k)
    normplot(v2(catresponse == cats{k}))
    jbResults(k) = jbtest(v2(catresponse == cats{k}));
    title(cats{k})
end % for
display(jbResults)

figure(figOpts{:})
for k = numel(cats):-1:1
    subplot(1, numel(cats), k)
    normplot(v3(catresponse == cats{k}))
    jbResults(k) = jbtest(v3(catresponse == cats{k}));
    title(cats{k})
end % for
display(jbResults)

figure(figOpts{:})
for k = numel(cats):-1:1
    subplot(1, numel(cats), k)
    normplot(v4(catresponse == cats{k}))
    jbResults(k) = jbtest(v4(catresponse == cats{k}));
    title(cats{k})
end % for
display(jbResults)

figure(figOpts{:})
for k = numel(cats):-1:1
    subplot(1, numel(cats), k)
    normplot(v5(catresponse == cats{k}))
    jbResults(k) = jbtest(v5(catresponse == cats{k}));
    title(cats{k})
end % for
display(jbResults)

figure(figOpts{:})
for k = numel(cats):-1:1
    subplot(1, numel(cats), k)
    normplot(v6(catresponse == cats{k}))
    jbResults(k) = jbtest(v6(catresponse == cats{k}));
    title(cats{k})
end % for
display(jbResults)

figure(figOpts{:})
for k = numel(cats):-1:1
    subplot(1, numel(cats), k)
    normplot(v7(catresponse == cats{k}))
    jbResults(k) = jbtest(v7(catresponse == cats{k}));
    title(cats{k})
end % for
display(jbResults)
% We see that the Normality assumption is violated for both the inactive
% and active classes in all the continuous variables

%% Fit the Naive Bayes classifier across all variables, specifying kernel smoothing densities.
% Identify categorical predictor variables.
catPreds = varfun(@iscategorical,finalnbs(:,2:24),'output','uniform');
% Fit the model, specifying a kernel distribution for continuous predictors
% and a multivariate multinomial distribution for categorical predictors.
dists = repmat({'kernel'}, 1, size(predictormatrix, 2));
dists(catPreds) = {'mvmn'};
nbModel = fitcnb(XTrain, yTrain, 'CategoricalPredictors', catPreds, ...
                                 'DistributionNames', dists);
% Use "normal" or "kernel" for continuous predictors/features. Use "mn" or
% "mvmn" for discrete/binomial/multinomial/categorical predictors.
nbPred = predict(nbModel, XTest);
% Evaluate misclassification rate.
testErrRateNB = 100*loss(nbModel, XTest, yTest);
display(testErrRateNB)

% Perform 10-fold cross validation.
% cvModel = crossval(nbModel); % 10-fold is default 
% cvErrornb = 100*kfoldLoss(cvModel);
% display(cvErrornb)
% Confusion matrix.
C = confusionmat(yTest, nbPred);
figure(figOpts{:})
imagesc(C)
colorbar
colormap('cool')
[Xgrid, Ygrid] = meshgrid(1:size(C, 1));
Ctext = num2str(C(:));
text(Xgrid(:), Ygrid(:), Ctext)
labels = categories(catresponse);
set(gca, 'XTick', 1:size(C, 1), 'XTickLabel', labels, ...
         'YTick', 1:size(C, 1), 'YTickLabel', labels, ...
         'XTickLabelRotation', 30, ...
         'TickLabelInterpreter', 'none')
xlabel('Predicted Class')
ylabel('Known Class')
title('Naive Bayes Confusion Matrix')

%% Discriminant analysis.

% Assumptions in discriminant analysis.
% * Normally distributed feature variables.
% * Types of boundaries can be specified based on the covariance matrices
% for each class.
% * Examine covariance matrix of the feature variables, as well as the
% variances by class.

% Compute the covariance matrix.
c = cov(predictormatrix);
% Visualize with a heatmap.
figure(figOpts{:})
imagesc(log(c + abs(min(c(:))) + 1))
colorbar
colormap(jet(64))
set(gca, 'XTick', 1:size(c, 1), ...
         'YTick', 1:size(c, 1), ...
         'XTickLabel', predictortable.Properties.VariableNames, ...
         'YTickLabel', predictortable.Properties.VariableNames, ...
         'XTickLabelRotation', 30, ...
         'TickLabelInterpreter', 'none')
title('Log of Shifted Covariance Matrix of Feature Matrix')

%% Test variance across data features using vartestn.
convertednbsX = convertednbs(:,2:24);
convertednbsXarray = table2array(convertednbsX);
p = vartestn(convertednbsXarray, 'TestType', 'BrownForsythe');
% The output p is the p-value of the test. The null hypothesis states that
% the variances are equal across all variables. The alternative hypothesis
% is that at least one column has a different variance from the others. A
% small p-value (e.g. < 0.05) indicates rejection of the null hypothesis.
% For non-Normal data, the Levene, Brown-Forsythe or O'Brien test can be
% used, as they are less sensitive to departures from Normality than
% Bartlett's test.
display(p)

%% Test variance for a single variable by group.
pClassVar1 = vartestn(v5, catresponse);
display(pClassVar1)
% Null hypothesis: same variance across all groups. Obtaining a small
% p-value provides evidence against the null hypothesis.

% Equality implies that we can use linear discriminant analysis.
% Otherwise, we consider using another approach, such as quadratic 
% discriminant analysis.

%% Fit the model.
% Based on the above analysis we will use a nonlinear discriminant
% analysis. The inactive category does not have enough observations to fit
% the model, so I used pseudoLinear
daModel = fitcdiscr(XTrain, yTrain, ...
    'DiscrimType', 'pseudoLinear');

% Evaluate the model effectiveness.
daPred = predict(daModel, XTest);
errs = daPred ~= yTest;
testErrRateDA = 100*sum(errs)/numel(errs);
display(testErrRateDA);

% Perform 10-fold cross validation.
% cvModel = crossval(daModel); % 10-fold is default 
% cvErrorDA = 100*kfoldLoss(cvModel);
% display(cvErrorDA)

% Confusion matrix.
C = confusionmat(yTest, daPred);
figure(figOpts{:})
imagesc(C)
colorbar
colormap('cool')
[Xgrid, Ygrid] = meshgrid(1:size(C, 1));
Ctext = num2str(C(:));
text(Xgrid(:), Ygrid(:), Ctext)
labels = categories(catresponse);
set(gca, 'XTick', 1:size(C, 1), 'XTickLabel', labels, ...
         'YTick', 1:size(C, 1), 'YTickLabel', labels, ...
         'XTickLabelRotation', 30, ...
         'TickLabelInterpreter', 'none')
xlabel('Predicted Class')
ylabel('Known Class')
title('Discriminant Analysis Confusion Matrix')

clearvars v1 v2 v3 v4 v5 v6 v7 Xgrid Ygrid p k jbResults Ctext;

%% Classification trees.
% * Trees are weak learners. Sensitive to training data. Better to use a 
%   forest of trees (ensemble/TreeBagger) rather than a single tree.
% * Trees classify based on a sequence of binary decisions taken on the
%   predictor variable values.
varsToKeep = convertednbsX.Properties.VariableNames;
% Create a single tree initially.
treeModel = fitctree(XTrain, yTrain, 'PredictorNames', varsToKeep, ...
     'CategoricalPredictors', catPreds);
% Inspect it.
view(treeModel, 'Mode', 'graph')
% Use the tree to make predictions.
treePred = predict(treeModel, XTest);
% Evaluate the error rate.
errs = treePred ~= yTest;
testErrRateTree = 100*sum(errs)/numel(errs);
display(testErrRateTree)

% Perform 10-fold cross validation.
% cvModel = crossval(treeModel); % 10-fold is default 
% cvErrorTree = 100*kfoldLoss(cvModel);
% display(cvErrorTree)

% Confusion matrix.
C = confusionmat(yTest, treePred);
figure(figOpts{:})
imagesc(C)
colorbar
colormap('cool')
[Xgrid, Ygrid] = meshgrid(1:size(C, 1));
Ctext = num2str(C(:));
text(Xgrid(:), Ygrid(:), Ctext)
labels = categories(catresponse);
set(gca, 'XTick', 1:size(C, 1), 'XTickLabel', labels, ...
         'YTick', 1:size(C, 1), 'YTickLabel', labels, ...
         'XTickLabelRotation', 30, ...
         'TickLabelInterpreter', 'none')
xlabel('Predicted Class')
ylabel('Known Class')
title('Single Decision Tree Confusion Matrix')

countrycomparison = [cellstr(finalnbs.Timezone) num2cell(zscorenbs.Timezone)];
bookmarkcomparison = [num2cell(finalnbs.bookmarks) num2cell(zscorenbs.bookmarks)];


% Note: we can use FITRTREE for continuous response variables (to use 
% trees as a nonparametric regression technique).

%% Assessing predictor variable importance.
% We can use the predictor importance function with the classification 
% tree. This works by summing changes in the mean-squared error due to 
% splits on each predictor and dividing the sum by the number of branch 
% nodes.
p = predictorImportance(treeModel);
figure(figOpts{:})
bar(p)
xlabel('Variable')
ylabel('Predictor Importance')
title('Single Decision Tree Predictor Importance')
grid
set(gca, 'XTick', 1:numel(varsToKeep), ...
    'XTickLabel', varsToKeep, ...
    'XTickLabelRotation', 30, ...
    'TickLabelInterpreter', 'none')

% Sort by predictor importance and visualize.
[~, sortPos] = sort(p, 'ascend');

figure(figOpts{:})
barh(p(sortPos))
set(gca, 'YTick', 1:numel(varsToKeep), ...
         'YTickLabel', varsToKeep(sortPos), ...
         'TickLabelInterpreter', 'none')
xlabel('Predictor Importance')
ylabel('Variable')
title('Single Decision Tree Predictor Importance')
grid

%% Determine the optimal level of tree pruning.
[~, ~, ~, bestk] = cvLoss(treeModel, 'Subtrees', 'all');
% Prune the tree.
prunedTree = prune(treeModel, 'level', bestk);
% Visualise it.
view(prunedTree, 'mode', 'graph')

% Evaluate the pruned tree.
prunedTreePred = predict(prunedTree, XTest);
errs = prunedTreePred ~= yTest;
testErrRatePrunedTree = 100*sum(errs)/numel(errs);
display(testErrRatePrunedTree)

% Perform 10-fold cross validation.
% cvModel = crossval(prunedTree); % 10-fold is default 
% cvErrorPrunedTree = 100*kfoldLoss(cvModel);
% display(cvErrorPrunedTree)

% Confusion matrix.
C = confusionmat(yTest, prunedTreePred);
figure(figOpts{:})
imagesc(C)
colorbar
colormap('cool')
[Xgrid, Ygrid] = meshgrid(1:size(C, 1));
Ctext = num2str(C(:));
text(Xgrid(:), Ygrid(:), Ctext)
labels = categories(catresponse);
set(gca, 'XTick', 1:size(C, 1), 'XTickLabel', labels, ...
         'YTick', 1:size(C, 1), 'YTickLabel', labels, ...
         'XTickLabelRotation', 30, ...
         'TickLabelInterpreter', 'none')
xlabel('Predicted Class')
ylabel('Known Class')
title('Pruned Decision Tree Confusion Matrix')

% % Perform cross validation of the model with different holdout.
% cvModel = crossval(prunedTree, 'Holdout', 0.5);  
% cvError = 100*kfoldLoss(cvModel);
% display(cvError)
% 
% % Perform 10-fold cross validation.
% cvModel = crossval(prunedTree); % 10-fold is default 
% cvError = 100*kfoldLoss(cvModel);
% display(cvError)

%% Ensembles of trees.
% Create an ensemble of 100 trees.
forestModel = fitensemble(XTrain, yTrain, 'Bag', 100,...
                            'Tree', 'Type', 'Classification'); 

% Predict and evaluate the ensemble model.
forestPred = predict(forestModel, XTest);
errs = forestPred ~= yTest;
testErrRateForest = 100*sum(errs)/numel(errs);
display(testErrRateForest)

% Perform 10-fold cross validation.
% cvModel = crossval(forestModel); % 10-fold is default 
% cvErrorForest = 100*kfoldLoss(cvModel);
% display(cvErrorForest)

% Confusion matrix.
C = confusionmat(yTest, forestPred);
figure(figOpts{:})
imagesc(C)
colorbar
colormap('cool')
[Xgrid, Ygrid] = meshgrid(1:size(C, 1));
Ctext = num2str(C(:));
text(Xgrid(:), Ygrid(:), Ctext)
labels = categories(catresponse);
set(gca, 'XTick', 1:size(C, 1), 'XTickLabel', labels, ...
         'YTick', 1:size(C, 1), 'YTickLabel', labels, ...
         'XTickLabelRotation', 30, ...
         'TickLabelInterpreter', 'none')
xlabel('Predicted Class')
ylabel('Known Class')
title('Forest Confusion Matrix')

%% Support Vector Machines (SVM).
% * Classifies data by finding the best separating hyperplane.
% * This may not be possible for certain data sets, so a solution is not
% guaranteed to exist.
% * Can be more generalisable than discriminant analysis.
% * Nonlinear separating curves are possible if a hyperplane cannot be
% found.
% * Support vectors are the data points closest to the separating curve.
% * Raw SVM is a binary classification algorithm. To implement multiclass
% SVM, we need to create an error-correcting output codes (ECOC)
% classifier, which reduces a multiclass learning problem to multiple
% binary classifiers.
% * Use FITCSVM for a binary classification.

% kernelModel = fitcsvm(XTrain, yTrain);% Haven't specified a kernelfunction here

t = templateSVM('KernelFunction', 'polynomial', ...
    'PolynomialOrder', 1); 
ecocModel = fitcecoc(XTrain, yTrain, 'Learners', t);

% Evaluate error rate.
svmPred = predict(ecocModel, XTest);
errs = svmPred ~= yTest;
testErrRateSVM = 100*sum(errs)/numel(errs);
display(testErrRateSVM)

% Perform 10-fold cross validation.
% cvModel = crossval(ecocModel); % 10-fold is default 
% cvErrorForestSVM = 100*kfoldLoss(cvModel);
% display(cvErrorForestSVM)

% Confusion matrix.
C = confusionmat(yTest, svmPred);
figure(figOpts{:})
imagesc(C)
colorbar
colormap('cool')
[Xgrid, Ygrid] = meshgrid(1:size(C, 1));
Ctext = num2str(C(:));
text(Xgrid(:), Ygrid(:), Ctext)
labels = categories(catresponse);
set(gca, 'XTick', 1:size(C, 1), 'XTickLabel', labels, ...
         'YTick', 1:size(C, 1), 'YTickLabel', labels, ...
         'XTickLabelRotation', 30, ...
         'TickLabelInterpreter', 'none')
xlabel('Predicted Class')
ylabel('Known Class')
title('SVM Confusion Matrix')

%% Final optimisation by removing unnecessary, highly correlated variables

% Create the training and test data sets.
chosenIndex = [1:3, 9, 16:17,19:20];
% The most important predictors are bookmarks,
% Facebook connected, is premier, has account.
newpredictormatrix = predictormatrix(:,chosenIndex);
rng default;
XTrain2 = newpredictormatrix(trainIdx, :);%Remove the connected_variables, and any
% other correlated variables, and see if this reduces the error rate
% massively
XTest2 = newpredictormatrix(testIdx, :);
% 
% Create an ensemble of 100 trees.
forestModel2 = fitensemble(XTrain2, yTrain, 'Bag', 100,...
                            'Tree', 'Type', 'Classification'); 

% Predict and evaluate the ensemble model.
forestPred2 = predict(forestModel2, XTest2);
errs2 = forestPred2 ~= yTest;
testErrorRateForestFinal = 100*sum(errs2)/numel(errs2);
display(testErrorRateForestFinal)

% Perform 10-fold cross validation.
% cvModel = crossval(forestModel2); % 10-fold is default 
% cvErrorForestFinal = 100*kfoldLoss(cvModel);
% display(cvErrorForestFinal)

% view(cvModel.Trained{1},'mode','graph')
% view(cvModel.Trained{2},'mode','graph') 

% cvModel.kfoldLoss('mode','individual')
% 
% forestPred2 = kfoldPredict(forestModel2, XTest2);

% Confusion matrix.
C = confusionmat(yTest, forestPred2);
figure(figOpts{:})
imagesc(C)
colorbar
colormap('cool')
[Xgrid, Ygrid] = meshgrid(1:size(C, 1));
Ctext = num2str(C(:));
text(Xgrid(:), Ygrid(:), Ctext)
labels = categories(catresponse);
set(gca, 'XTick', 1:size(C, 1), 'XTickLabel', labels, ...
         'YTick', 1:size(C, 1), 'YTickLabel', labels, ...
         'XTickLabelRotation', 30, ...
         'TickLabelInterpreter', 'none')
xlabel('Predicted Class')
ylabel('Known Class')
title('Forest Confusion Matrix 2')

%% Assemble the results of all the classifiers.
classMethods = {'Dumb Prediction';...
                'KNearestNeighbours'; ...
                'NaiveBayes'; ...
                'DiscriminantAnalysis'; ...
                'DecisionTree'; ...
                'PrunedDecisionTree'; ...
                'RandomForest'; ...
                'SupportVectorMachines';...
                'TargetedRandomForest'};
classErrRates = [testErrRateDum;...
                 testErrRateKNN; ...                    
                 testErrRateNB; ...
                 testErrRateDA; ...
                 testErrRateTree; ...
                 testErrRatePrunedTree; ...
                 testErrRateForest; ...
                 testErrRateSVM;...
                 testErrorRateForestFinal];
classificationResults = table(classMethods, classErrRates, ...
    'VariableNames', {'Method', 'ErrorRate'});
classificationResults = sortrows(classificationResults, ...
    'ErrorRate', 'descend');
display(classificationResults)


%% Fit a logistic regression with the chosen variables
% 
% [B,dev,stats] = mnrfit(newpredictormatrix,numresponse);

%% Attempt a lasso and elastic net implementation
% http://uk.mathworks.com/help/stats/lasso.html
% http://uk.mathworks.com/help/stats/lasso-and-elastic-net.html
% http://www.mathworks.com/matlabcentral/answers/10273-why-do-i-receive-cell-contents-reference-from-a-non-cell-array-object-error
labels = balancedfinalnbs(:,2:8).Properties.VariableNames.';
[w1, stats1] = lasso(XTrainLasso,yTrainLasso, 'Alpha', 0.5, 'Lambda', 0.03,'Standardize',true);
[w2, stats2] = lasso(XTrainLasso,yTrainLasso,'Lambda',0.03,'Standardize',true);
[w3, stats3] = lasso(XTrainLasso,yTrainLasso,'Alpha',0.01,'Lambda',0.03,'Standardize',true);
[w4, stats4] = lasso(contpredictormatrix,contresponse,'CV',10,'Alpha',0.5,'Lambda',0.03,'Standardize',true);
lassoResults = table(w1, w2,w3,w4,'RowNames',labels);
display(lassoResults)
MSE = [stats1.MSE,stats2.MSE,stats3.MSE,stats4.MSE];
MSEResults = table(MSE.','RowNames',{'5050 Lasso/Ridge','Lasso','Ridge','10 Fold Cross Val'});
MSEResults.Properties.VariableNames{'Var1'} = 'Mean_Squared_Error';
display(MSEResults)